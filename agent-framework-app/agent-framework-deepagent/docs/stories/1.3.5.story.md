# Story 1.3.5: API Integration Testing Harness

## Status: Draft

## Story
As a developer, I want an automated integration testing harness for the generation and visualization APIs, so that regressions are caught before UI integration.

## Acceptance Criteria
1. Test runner configured (e.g., pytest + requests or httpx) with a dedicated `tests/integration` directory.
2. A Docker Compose or local script starts backend dependencies (DB + backend service) for tests.
3. Tests cover happy path for `/api/generate-workflow` (valid prompt returns Python code).
4. Tests cover error handling (empty prompt, invalid payload).
5. Tests for `/api/visualize-workflow` using sample Python code produce a Mermaid definition.
6. Round-trip test: generation output fed into visualization endpoint successfully.
7. Basic performance assertion: each endpoint responds < 1s under local dev conditions.
8. CI workflow placeholder or script stub added for future automation.

## Dev Notes
- Use pytest + requests/httpx for integration tests.
- Docker Compose for backend dependencies.
- Cover happy path, error handling, round-trip, and performance.
- Add CI workflow placeholder.

## Tasks / Subtasks
- [ ] Configure test runner and integration test directory.
- [ ] Create Docker Compose/local script for backend dependencies.
- [ ] Write tests for `/api/generate-workflow` (happy path, errors).
- [ ] Write tests for `/api/visualize-workflow` (happy path, errors).
- [ ] Implement round-trip test.
- [ ] Add basic performance assertion (<1s response).
- [ ] Add CI workflow placeholder/script stub.

## Project Structure Notes
- Integration tests in `apps/backend/app/tests/integration/`.
- Update CI workflow documentation.

## Testing
- Backend: pytest for integration tests.
- Performance: Measure endpoint response times.

## QA Results

## File List

## Dev Agent Record
- Agent Model Used:
- Debug Log References:
- Completion Notes List:
- Change Log:
